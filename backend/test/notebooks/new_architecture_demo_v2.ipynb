{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ–°æ¶æ§‹ç¤ºç¯„ V2 / New Architecture Demo V2\n",
    "\n",
    "å±•ç¤º KEEN æ–°æ¶æ§‹çš„ä½¿ç”¨æ–¹å¼ï¼ŒåŒ…å« IDE å‹å¥½çš„ä»‹é¢å’Œç›´è¦ºçš„è³‡æ–™å­˜å–  \n",
    "Demonstrates the usage of KEEN's new architecture with IDE-friendly interface and intuitive data access\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ä¸»è¦æ”¹é€² / Key Improvements\n",
    "\n",
    "âœ… **IDE å‹å¥½çš„å‹åˆ¥æç¤º**ï¼š`session['file'].data.attribute`  \n",
    "âœ… **å®Œæ•´çš„ç‹€æ…‹ç®¡ç†**ï¼šæ‰€æœ‰åˆ†æçµæœè‡ªå‹•æŒä¹…åŒ–  \n",
    "âœ… **çµ±ä¸€çš„è³‡æ–™æ ¼å¼**ï¼šæ¨™æº–åŒ–çš„ `ParseResult` å’Œè³‡æ–™æ¨¡å‹  \n",
    "âœ… **æ¸…æ™°çš„è·è²¬åˆ†é›¢**ï¼šå‹åˆ¥ç®¡ç†å™¨æ¨¡å¼  \n",
    "âœ… **æ­£ç¢ºçš„ Scale è™•ç†**ï¼šå¾ TXT æª”æ¡ˆç²å–æ­£ç¢ºçš„æ•¸å€¼ scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ç’°å¢ƒè¨­å®š / Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’» ç•¶å‰å·¥ä½œç›®éŒ„: /Users/yangziliang/Git-Projects/keen/backend/test\n",
      "ğŸ’» å¾Œç«¯è·¯å¾‘: /Users/yangziliang/Git-Projects/keen/backend\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ å¾Œç«¯è·¯å¾‘åˆ° Python è·¯å¾‘ / Add backend path to Python path\n",
    "backend_path = Path.cwd().parent if Path.cwd().name == 'test' else Path.cwd()\n",
    "sys.path.insert(0, str(backend_path))\n",
    "\n",
    "print(f\"ğŸ’» ç•¶å‰å·¥ä½œç›®éŒ„: {Path.cwd()}\")\n",
    "print(f\"ğŸ’» å¾Œç«¯è·¯å¾‘: {backend_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–°æ¶æ§‹æ¨¡çµ„åŒ¯å…¥æˆåŠŸï¼\n",
      "âœ… New architecture modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# åŒ¯å…¥æ–°æ¶æ§‹çš„æ ¸å¿ƒæ¨¡çµ„\n",
    "from core.experiment_session import ExperimentSession\n",
    "from core.data_models import TopoData, CitsData, TxtData\n",
    "\n",
    "print(\"âœ… æ–°æ¶æ§‹æ¨¡çµ„åŒ¯å…¥æˆåŠŸï¼\")\n",
    "print(\"âœ… New architecture modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆ / Check Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ æ¸¬è©¦æª”æ¡ˆç›®éŒ„: /Users/yangziliang/Git-Projects/keen/testfile\n",
      "ğŸ“ æ‰¾åˆ° 1 å€‹ TXT æª”æ¡ˆ:\n",
      "   1. 20250521_Janus Stacking SiO2_13K_113.txt\n",
      "\n",
      "ğŸ¯ å°‡ä½¿ç”¨: 20250521_Janus Stacking SiO2_13K_113.txt\n"
     ]
    }
   ],
   "source": [
    "# æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "testfile_dir = backend_path.parent / \"testfile\"\n",
    "txt_files = list(testfile_dir.glob(\"*.txt\"))\n",
    "\n",
    "print(f\"ğŸ“ æ¸¬è©¦æª”æ¡ˆç›®éŒ„: {testfile_dir}\")\n",
    "print(f\"ğŸ“ æ‰¾åˆ° {len(txt_files)} å€‹ TXT æª”æ¡ˆ:\")\n",
    "\n",
    "for i, txt_file in enumerate(txt_files):\n",
    "    print(f\"   {i+1}. {txt_file.name}\")\n",
    "\n",
    "if txt_files:\n",
    "    selected_txt = txt_files[0]\n",
    "    print(f\"\\nğŸ¯ å°‡ä½¿ç”¨: {selected_txt.name}\")\n",
    "else:\n",
    "    print(\"âŒ æœªæ‰¾åˆ°æ¸¬è©¦æª”æ¡ˆï¼è«‹ç¢ºä¿ testfile ç›®éŒ„ä¸­æœ‰ .txt æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ åˆå§‹åŒ–å¯¦é©—æœƒè©± / Initialize Experiment Session\n",
    "\n",
    "æ–°æ¶æ§‹çš„æ ¸å¿ƒæ˜¯ `ExperimentSession`ï¼Œå®ƒæ•´åˆäº†æ‰€æœ‰çš„å‹åˆ¥ç®¡ç†å™¨å’Œæä¾›çµ±ä¸€çš„ä»‹é¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ åˆå§‹åŒ–å¯¦é©—æœƒè©±...\n",
      "âœ… æœƒè©±å»ºç«‹æˆåŠŸï¼\n",
      "ğŸ“Š å¯¦é©—åç¨±: Unknown\n",
      "ğŸ“Š TXT æª”æ¡ˆ: 20250521_Janus Stacking SiO2_13K_113.txt\n",
      "ğŸ“Š å»ºç«‹æ™‚é–“: 2025-06-07 16:33:10\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–å¯¦é©—æœƒè©± - é€™æ˜¯æ–°æ¶æ§‹çš„ä¸»è¦å…¥å£\n",
    "if txt_files:\n",
    "    print(\"ğŸš€ åˆå§‹åŒ–å¯¦é©—æœƒè©±...\")\n",
    "    session = ExperimentSession(str(selected_txt))\n",
    "    \n",
    "    print(f\"âœ… æœƒè©±å»ºç«‹æˆåŠŸï¼\")\n",
    "    print(f\"ğŸ“Š å¯¦é©—åç¨±: {session.experiment_name}\")\n",
    "    print(f\"ğŸ“Š TXT æª”æ¡ˆ: {session.txt_file_path.name}\")\n",
    "    print(f\"ğŸ“Š å»ºç«‹æ™‚é–“: {session.creation_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "else:\n",
    "    print(\"âŒ ç„¡æ³•åˆå§‹åŒ–æœƒè©±ï¼Œè«‹æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ æª¢è¦–æœƒè©±æ‘˜è¦ / View Session Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æœƒè©±æ‘˜è¦ / Session Summary\n",
      "========================================\n",
      "å¯¦é©—åç¨±: Unknown\n",
      "ç¸½æª”æ¡ˆæ•¸: 17\n",
      "  - TXT: 1\n",
      "  - TOPO: 12\n",
      "  - CITS: 4\n",
      "  - STS: 0\n",
      "\n",
      "ğŸ”¬ æƒæåƒæ•¸:\n",
      "  - åƒç´ æ•¸: 500 Ã— 500\n",
      "  - æƒæç¯„åœ: 10.0 Ã— 10.0 nm\n",
      "  - X åƒç´ å°ºåº¦: 0.0200 nm/pixel\n",
      "  - Y åƒç´ å°ºåº¦: 0.0200 nm/pixel\n"
     ]
    }
   ],
   "source": [
    "# é¡¯ç¤ºæœƒè©±æ‘˜è¦ - äº†è§£æœ‰å“ªäº›æª”æ¡ˆå¯ç”¨\n",
    "if 'session' in locals():\n",
    "    summary = session.get_session_summary()\n",
    "    files_summary = summary['files_summary']\n",
    "    \n",
    "    print(\"ğŸ“Š æœƒè©±æ‘˜è¦ / Session Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"å¯¦é©—åç¨±: {summary['experiment_name']}\")\n",
    "    print(f\"ç¸½æª”æ¡ˆæ•¸: {files_summary['total_available']}\")\n",
    "    print(f\"  - TXT: {files_summary['available']['txt']}\")\n",
    "    print(f\"  - TOPO: {files_summary['available']['topo']}\")\n",
    "    print(f\"  - CITS: {files_summary['available']['cits']}\")\n",
    "    print(f\"  - STS: {files_summary['available']['sts']}\")\n",
    "    \n",
    "    # é¡¯ç¤ºæƒæåƒæ•¸\n",
    "    scan_params = summary.get('scan_parameters')\n",
    "    if scan_params:\n",
    "        print(f\"\\nğŸ”¬ æƒæåƒæ•¸:\")\n",
    "        print(f\"  - åƒç´ æ•¸: {scan_params['x_pixel']} Ã— {scan_params['y_pixel']}\")\n",
    "        print(f\"  - æƒæç¯„åœ: {scan_params['x_range']:.1f} Ã— {scan_params['y_range']:.1f} nm\")\n",
    "        print(f\"  - X åƒç´ å°ºåº¦: {scan_params['pixel_scale_x']:.4f} nm/pixel\")\n",
    "        print(f\"  - Y åƒç´ å°ºåº¦: {scan_params['pixel_scale_y']:.4f} nm/pixel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ æ–°çš„æª”æ¡ˆå­˜å–æ–¹å¼ / New File Access Methods\n",
    "\n",
    "### èˆŠæ–¹å¼ vs æ–°æ–¹å¼å°æ¯”\n",
    "\n",
    "**âŒ èˆŠæ–¹å¼ (è¤‡é›œä¸”å®¹æ˜“å‡ºéŒ¯):**\n",
    "```python\n",
    "data = analyzer.experiment_data['loaded_files']['topofwd']['data']['image_data']\n",
    "scale = analyzer.experiment_data['txt_data']['scan_parameters']['x_range']\n",
    "```\n",
    "\n",
    "**âœ… æ–°æ–¹å¼ (IDE å‹å¥½ä¸”ç›´è¦º):**\n",
    "```python\n",
    "topo = session['topofwd']        # FileProxy with full type hints\n",
    "data = topo.data.image           # TopoData.image: np.ndarray\n",
    "scale = topo.data.x_range        # TopoData.x_range: float\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ å¯ç”¨æª”æ¡ˆåˆ—è¡¨ / Available Files:\n",
      "========================================\n",
      "\n",
      "ğŸ“ TXT æª”æ¡ˆ (1 å€‹):\n",
      "   1. 20250521_Janus Stacking SiO2_13K_113\n",
      "\n",
      "ğŸ“ TOPO æª”æ¡ˆ (12 å€‹):\n",
      "   1. 20250521_Janus Stacking SiO2_13K_113TopoFwd\n",
      "   2. 20250521_Janus Stacking SiO2_13K_113TopoBwd\n",
      "   3. 20250521_Janus Stacking SiO2_13K_113Lia1XFwd\n",
      "   4. 20250521_Janus Stacking SiO2_13K_113Lia1XBwd\n",
      "   5. 20250521_Janus Stacking SiO2_13K_113Lia1YFwd\n",
      "   ... é‚„æœ‰ 7 å€‹æª”æ¡ˆ\n",
      "\n",
      "ğŸ“ CITS æª”æ¡ˆ (4 å€‹):\n",
      "   1. 20250521_Janus Stacking SiO2_13K_113It_to_PC_Matrix\n",
      "   2. 20250521_Janus Stacking SiO2_13K_113Lia1R_Matrix\n",
      "   3. 20250521_Janus Stacking SiO2_13K_113Lia1Y_Matrix\n",
      "   4. 20250521_Janus Stacking SiO2_13K_113Lia2R_Matrix\n"
     ]
    }
   ],
   "source": [
    "# åˆ—å‡ºå¯ç”¨æª”æ¡ˆ\n",
    "if 'session' in locals():\n",
    "    available_files = session.available_files\n",
    "    \n",
    "    print(\"ğŸ“‹ å¯ç”¨æª”æ¡ˆåˆ—è¡¨ / Available Files:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for file_type, files in available_files.items():\n",
    "        if files:\n",
    "            print(f\"\\nğŸ“ {file_type.upper()} æª”æ¡ˆ ({len(files)} å€‹):\")\n",
    "            for i, file_key in enumerate(files[:5]):  # åªé¡¯ç¤ºå‰5å€‹\n",
    "                print(f\"   {i+1}. {file_key}\")\n",
    "            if len(files) > 5:\n",
    "                print(f\"   ... é‚„æœ‰ {len(files)-5} å€‹æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ æ¸¬è©¦æ‹“æ’²æª”æ¡ˆå­˜å– / Test Topography File Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” æ¸¬è©¦æª”æ¡ˆ: 20250521_Janus Stacking SiO2_13K_113TopoFwd\n",
      "========================================\n",
      "ğŸ“Š æª”æ¡ˆè³‡è¨Š:\n",
      "  - æª”æ¡ˆé¡å‹: topo\n",
      "  - å·²è¼‰å…¥: False\n",
      "  - æª”æ¡ˆå¤§å°: 976.6 KB\n",
      "  - è¨Šè™Ÿé¡å‹: Topo\n",
      "  - æƒææ–¹å‘: Fwd\n"
     ]
    }
   ],
   "source": [
    "# é¸æ“‡ä¸€å€‹æ‹“æ’²æª”æ¡ˆé€²è¡Œæ¸¬è©¦\n",
    "if 'session' in locals() and session.available_files['topo']:\n",
    "    topo_key = session.available_files['topo'][0]\n",
    "    print(f\"ğŸ” æ¸¬è©¦æª”æ¡ˆ: {topo_key}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # ä½¿ç”¨æ–°çš„ç›´è¦ºå­˜å–æ–¹å¼\n",
    "    topo = session[topo_key]\n",
    "    \n",
    "    print(f\"ğŸ“Š æª”æ¡ˆè³‡è¨Š:\")\n",
    "    print(f\"  - æª”æ¡ˆé¡å‹: {topo.file_type}\")\n",
    "    print(f\"  - å·²è¼‰å…¥: {topo.is_loaded}\")\n",
    "    \n",
    "    if topo.file_info:\n",
    "        info = topo.file_info\n",
    "        print(f\"  - æª”æ¡ˆå¤§å°: {info.human_readable_size}\")\n",
    "        print(f\"  - è¨Šè™Ÿé¡å‹: {info.signal_type}\")\n",
    "        print(f\"  - æƒææ–¹å‘: {info.direction}\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ç”¨çš„æ‹“æ’²æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ è¼‰å…¥æ‹“æ’²æ•¸æ“š...\n",
      "\n",
      "âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼\n",
      "ğŸ“Š æ‹“æ’²æ•¸æ“šè³‡è¨Š:\n",
      "  - åœ–åƒå°ºå¯¸: (500, 500)\n",
      "  - X ç¯„åœ: 10.00 nm\n",
      "  - Y ç¯„åœ: 10.00 nm\n",
      "  - X åƒç´ å°ºåº¦: 0.0200 nm/pixel\n",
      "  - Y åƒç´ å°ºåº¦: 0.0200 nm/pixel\n",
      "  - æ•¸å€¼ Scale: -2.60913687478663e-07\n",
      "  - è¨Šè™Ÿé¡å‹: Topo\n",
      "  - æƒææ–¹å‘: Fwd\n",
      "\n",
      "ğŸ“ˆ æ•¸æ“šçµ±è¨ˆ:\n",
      "  - æœ€å°å€¼: -93.305322\n",
      "  - æœ€å¤§å€¼: -91.885328\n",
      "  - å¹³å‡å€¼: -92.788010\n",
      "  - æ¨™æº–å·®: 0.197238\n"
     ]
    }
   ],
   "source": [
    "# è¼‰å…¥ä¸¦æª¢è¦–æ‹“æ’²æ•¸æ“š\n",
    "if 'topo' in locals():\n",
    "    try:\n",
    "        print(\"ğŸ“¥ è¼‰å…¥æ‹“æ’²æ•¸æ“š...\")\n",
    "        data = topo.data  # é€™æœƒè‡ªå‹•è§¸ç™¼è¼‰å…¥\n",
    "        \n",
    "        if isinstance(data, TopoData):\n",
    "            print(\"\\nâœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼\")\n",
    "            print(f\"ğŸ“Š æ‹“æ’²æ•¸æ“šè³‡è¨Š:\")\n",
    "            print(f\"  - åœ–åƒå°ºå¯¸: {data.shape}\")\n",
    "            print(f\"  - X ç¯„åœ: {data.x_range:.2f} nm\")\n",
    "            print(f\"  - Y ç¯„åœ: {data.y_range:.2f} nm\")\n",
    "            print(f\"  - X åƒç´ å°ºåº¦: {data.pixel_scale_x:.4f} nm/pixel\")\n",
    "            print(f\"  - Y åƒç´ å°ºåº¦: {data.pixel_scale_y:.4f} nm/pixel\")\n",
    "            print(f\"  - æ•¸å€¼ Scale: {data.data_scale}\")\n",
    "            print(f\"  - è¨Šè™Ÿé¡å‹: {data.signal_type}\")\n",
    "            print(f\"  - æƒææ–¹å‘: {data.direction}\")\n",
    "            \n",
    "            # é¡¯ç¤ºæ•¸æ“šçµ±è¨ˆ\n",
    "            image = data.image\n",
    "            print(f\"\\nğŸ“ˆ æ•¸æ“šçµ±è¨ˆ:\")\n",
    "            print(f\"  - æœ€å°å€¼: {image.min():.6f}\")\n",
    "            print(f\"  - æœ€å¤§å€¼: {image.max():.6f}\")\n",
    "            print(f\"  - å¹³å‡å€¼: {image.mean():.6f}\")\n",
    "            print(f\"  - æ¨™æº–å·®: {image.std():.6f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¼‰å…¥å¤±æ•—: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ æ¸¬è©¦ CITS æª”æ¡ˆå­˜å– / Test CITS File Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ æ¸¬è©¦ CITS æª”æ¡ˆ: 20250521_Janus Stacking SiO2_13K_113It_to_PC_Matrix\n",
      "========================================\n",
      "ğŸ“Š CITS æª”æ¡ˆè³‡è¨Š:\n",
      "  - æª”æ¡ˆé¡å‹: cits\n",
      "  - å·²è¼‰å…¥: False\n",
      "\n",
      "ğŸ“¥ è¼‰å…¥ CITS æ•¸æ“š...\n",
      "âœ… CITS æ•¸æ“šè¼‰å…¥æˆåŠŸï¼\n",
      "  - 3D æ•¸æ“šå½¢ç‹€: (401, 100, 100)\n",
      "  - åå£“é»æ•¸: 401\n",
      "  - åå£“ç¯„åœ: -2050.000 ~ 1050.000 V\n",
      "  - ç¶²æ ¼å¤§å°: [100, 100]\n",
      "  - X ç¯„åœ: 100.00 nm\n",
      "  - Y ç¯„åœ: 100.00 nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangziliang/Git-Projects/keen/backend/core/parsers/dat_parser.py:84: DtypeWarning: Columns (0,1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='\\t', header=None)\n"
     ]
    }
   ],
   "source": [
    "# æ¸¬è©¦ CITS æª”æ¡ˆï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰\n",
    "if 'session' in locals() and session.available_files['cits']:\n",
    "    cits_key = session.available_files['cits'][0]\n",
    "    print(f\"ğŸ”¬ æ¸¬è©¦ CITS æª”æ¡ˆ: {cits_key}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        cits = session[cits_key]\n",
    "        print(f\"ğŸ“Š CITS æª”æ¡ˆè³‡è¨Š:\")\n",
    "        print(f\"  - æª”æ¡ˆé¡å‹: {cits.file_type}\")\n",
    "        print(f\"  - å·²è¼‰å…¥: {cits.is_loaded}\")\n",
    "        \n",
    "        # è¼‰å…¥ CITS æ•¸æ“š\n",
    "        print(\"\\nğŸ“¥ è¼‰å…¥ CITS æ•¸æ“š...\")\n",
    "        cits_data = cits.data\n",
    "        \n",
    "        if isinstance(cits_data, CitsData):\n",
    "            print(\"âœ… CITS æ•¸æ“šè¼‰å…¥æˆåŠŸï¼\")\n",
    "            print(f\"  - 3D æ•¸æ“šå½¢ç‹€: {cits_data.shape}\")\n",
    "            print(f\"  - åå£“é»æ•¸: {cits_data.n_bias_points}\")\n",
    "            print(f\"  - åå£“ç¯„åœ: {cits_data.bias_range[0]:.3f} ~ {cits_data.bias_range[1]:.3f} V\")\n",
    "            print(f\"  - ç¶²æ ¼å¤§å°: {cits_data.grid_size}\")\n",
    "            print(f\"  - X ç¯„åœ: {cits_data.x_range:.2f} nm\")\n",
    "            print(f\"  - Y ç¯„åœ: {cits_data.y_range:.2f} nm\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CITS è¼‰å…¥å¤±æ•—: {str(e)}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  æ²’æœ‰å¯ç”¨çš„ CITS æª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ åˆ†æå™¨åŠŸèƒ½æ¸¬è©¦ / Analyzer Features Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ æ¸¬è©¦åˆ†æå™¨åŠŸèƒ½\n",
      "========================================\n",
      "âœ… åˆ†æå™¨é¡å‹: IntAnalyzer\n",
      "\n",
      "ğŸ”§ å¯ç”¨çš„åˆ†ææ–¹æ³•:\n",
      "  - topo.flatten_plane()      # å¹³é¢å¹³å¦åŒ–\n",
      "  - topo.extract_profile()    # æå–å‰–é¢ç·š\n",
      "  - topo.analyzer             # ç²å–å®Œæ•´åˆ†æå™¨\n",
      "\n",
      "ğŸ“‹ åˆ†æå™¨æ–¹æ³• (25 å€‹):\n",
      "  - analysis_history\n",
      "  - analyze\n",
      "  - apply_flattening\n",
      "  - apply_tilt_correction\n",
      "  - cached_results\n",
      "  - clear_cache\n",
      "  - current_line_profile\n",
      "  - current_topo_data\n",
      "  - detect_features\n",
      "  - extract_line_profile\n",
      "  ... é‚„æœ‰ 15 å€‹æ–¹æ³•\n"
     ]
    }
   ],
   "source": [
    "# æ¸¬è©¦åˆ†æå™¨åŠŸèƒ½\n",
    "if 'topo' in locals():\n",
    "    print(\"ğŸ”§ æ¸¬è©¦åˆ†æå™¨åŠŸèƒ½\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # ç²å–åˆ†æå™¨\n",
    "        analyzer = topo.analyzer\n",
    "        print(f\"âœ… åˆ†æå™¨é¡å‹: {type(analyzer).__name__}\")\n",
    "        \n",
    "        # é¡¯ç¤ºå¯ç”¨çš„åˆ†ææ–¹æ³•\n",
    "        print(\"\\nğŸ”§ å¯ç”¨çš„åˆ†ææ–¹æ³•:\")\n",
    "        print(\"  - topo.flatten_plane()      # å¹³é¢å¹³å¦åŒ–\")\n",
    "        print(\"  - topo.extract_profile()    # æå–å‰–é¢ç·š\")\n",
    "        print(\"  - topo.analyzer             # ç²å–å®Œæ•´åˆ†æå™¨\")\n",
    "        \n",
    "        # æª¢æŸ¥åˆ†æå™¨æ˜¯å¦æœ‰å¸¸ç”¨æ–¹æ³•\n",
    "        methods = [attr for attr in dir(analyzer) if not attr.startswith('_')]\n",
    "        print(f\"\\nğŸ“‹ åˆ†æå™¨æ–¹æ³• ({len(methods)} å€‹):\")\n",
    "        for method in methods[:10]:  # åªé¡¯ç¤ºå‰10å€‹\n",
    "            print(f\"  - {method}\")\n",
    "        if len(methods) > 10:\n",
    "            print(f\"  ... é‚„æœ‰ {len(methods)-10} å€‹æ–¹æ³•\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ†æå™¨æ¸¬è©¦å¤±æ•—: {str(e)}\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ç”¨çš„æ‹“æ’²æª”æ¡ˆé€²è¡Œåˆ†æå™¨æ¸¬è©¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ æ‰¹æ¬¡æ“ä½œå’Œæœå°‹åŠŸèƒ½ / Batch Operations and Search Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ æ‰¹æ¬¡æ“ä½œå’Œæœå°‹åŠŸèƒ½æ¸¬è©¦\n",
      "========================================\n",
      "ğŸ“‚ æ‹“æ’²æª”æ¡ˆ (12 å€‹):\n",
      "  1. 20250521_Janus Stacking SiO2_13K_113TopoFwd (Topo Fwd) - 976.6 KB\n",
      "  2. 20250521_Janus Stacking SiO2_13K_113TopoBwd (Topo Bwd) - 976.6 KB\n",
      "  3. 20250521_Janus Stacking SiO2_13K_113Lia1XFwd (Lia1X Fwd) - 976.6 KB\n",
      "  4. 20250521_Janus Stacking SiO2_13K_113Lia1XBwd (Lia1X Bwd) - 976.6 KB\n",
      "  5. 20250521_Janus Stacking SiO2_13K_113Lia1YFwd (Lia1Y Fwd) - 976.6 KB\n",
      "  ... é‚„æœ‰ 7 å€‹æª”æ¡ˆ\n",
      "\n",
      "ğŸ” æœå°‹åŠŸèƒ½æ¸¬è©¦:\n",
      "  - Topo è¨Šè™Ÿæª”æ¡ˆ: 2 å€‹\n",
      "  - æ­£å‘æƒææª”æ¡ˆ: 6 å€‹\n",
      "  - åå‘æƒææª”æ¡ˆ: 6 å€‹\n"
     ]
    }
   ],
   "source": [
    "# æ¸¬è©¦æ‰¹æ¬¡æ“ä½œå’Œæœå°‹åŠŸèƒ½\n",
    "if 'session' in locals():\n",
    "    print(\"ğŸ“ æ‰¹æ¬¡æ“ä½œå’Œæœå°‹åŠŸèƒ½æ¸¬è©¦\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # ç²å–æ‰€æœ‰æ‹“æ’²æª”æ¡ˆ\n",
    "    topo_files = session.get_topo_files()\n",
    "    print(f\"ğŸ“‚ æ‹“æ’²æª”æ¡ˆ ({len(topo_files)} å€‹):\")\n",
    "    for i, file_key in enumerate(topo_files[:5]):\n",
    "        file_proxy = session[file_key]\n",
    "        info = file_proxy.file_info\n",
    "        signal_type = info.signal_type if info else \"Unknown\"\n",
    "        direction = info.direction if info else \"\"\n",
    "        size = info.human_readable_size if info else \"Unknown\"\n",
    "        print(f\"  {i+1}. {file_key} ({signal_type} {direction}) - {size}\")\n",
    "    \n",
    "    if len(topo_files) > 5:\n",
    "        print(f\"  ... é‚„æœ‰ {len(topo_files)-5} å€‹æª”æ¡ˆ\")\n",
    "    \n",
    "    # æ ¹æ“šè¨Šè™Ÿé¡å‹æœå°‹\n",
    "    print(\"\\nğŸ” æœå°‹åŠŸèƒ½æ¸¬è©¦:\")\n",
    "    topo_signal_files = session.find_files_by_signal_type(\"Topo\")\n",
    "    print(f\"  - Topo è¨Šè™Ÿæª”æ¡ˆ: {len(topo_signal_files)} å€‹\")\n",
    "    \n",
    "    # æ ¹æ“šæ–¹å‘æœå°‹\n",
    "    fwd_files = session.find_files_by_direction(\"Fwd\")\n",
    "    bwd_files = session.find_files_by_direction(\"Bwd\")\n",
    "    print(f\"  - æ­£å‘æƒææª”æ¡ˆ: {len(fwd_files)} å€‹\")\n",
    "    print(f\"  - åå‘æƒææª”æ¡ˆ: {len(bwd_files)} å€‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š / Memory Usage Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š\n",
      "========================================\n",
      "ğŸ“Š æ•´é«”ç‹€æ³:\n",
      "  - ç¸½æª”æ¡ˆæ•¸: 17\n",
      "  - å·²è¼‰å…¥æª”æ¡ˆ: 3\n",
      "  - æª”æ¡ˆä»£ç†å¿«å–: 6 å€‹\n",
      "\n",
      "ğŸ“ˆ å„ç®¡ç†å™¨å¿«å–ç‹€æ³:\n",
      "  - txt_cache: 1 å€‹ (å‘½ä¸­ç‡: 80.0%)\n",
      "  - topo_cache: 1 å€‹ (å‘½ä¸­ç‡: 0.0%)\n",
      "  - cits_cache: 1 å€‹ (å‘½ä¸­ç‡: 0.0%)\n",
      "  - sts_cache: 0 å€‹ (å‘½ä¸­ç‡: 0.0%)\n",
      "\n",
      "ğŸ“‚ å·²è¼‰å…¥æª”æ¡ˆè©³æƒ…:\n",
      "  - TXT: ['20250521_Janus Stacking SiO2_13K_113']\n",
      "  - TOPO: ['20250521_Janus Stacking SiO2_13K_113TopoFwd']\n",
      "  - CITS: ['20250521_Janus Stacking SiO2_13K_113It_to_PC_Matrix']\n"
     ]
    }
   ],
   "source": [
    "# æª¢è¦–è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š\n",
    "if 'session' in locals():\n",
    "    print(\"ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨è³‡è¨Š\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    memory_info = session.get_memory_info()\n",
    "    \n",
    "    print(f\"ğŸ“Š æ•´é«”ç‹€æ³:\")\n",
    "    print(f\"  - ç¸½æª”æ¡ˆæ•¸: {memory_info['total_files']}\")\n",
    "    print(f\"  - å·²è¼‰å…¥æª”æ¡ˆ: {memory_info['total_loaded']}\")\n",
    "    print(f\"  - æª”æ¡ˆä»£ç†å¿«å–: {memory_info['proxy_cache_size']} å€‹\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å„ç®¡ç†å™¨å¿«å–ç‹€æ³:\")\n",
    "    for manager_name, cache_info in memory_info.items():\n",
    "        if isinstance(cache_info, dict) and 'cache_size' in cache_info:\n",
    "            hit_rate = cache_info.get('hit_rate', 0) * 100\n",
    "            print(f\"  - {manager_name}: {cache_info['cache_size']} å€‹ (å‘½ä¸­ç‡: {hit_rate:.1f}%)\")\n",
    "    \n",
    "    # é¡¯ç¤ºå·²è¼‰å…¥æª”æ¡ˆ\n",
    "    loaded_files = session.loaded_files\n",
    "    total_loaded = sum(len(files) for files in loaded_files.values())\n",
    "    if total_loaded > 0:\n",
    "        print(f\"\\nğŸ“‚ å·²è¼‰å…¥æª”æ¡ˆè©³æƒ…:\")\n",
    "        for file_type, files in loaded_files.items():\n",
    "            if files:\n",
    "                print(f\"  - {file_type.upper()}: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ æ–°èˆŠæ¶æ§‹å®Œæ•´å°æ¯” / Complete Old vs New Architecture Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”„ ç¨‹å¼ç¢¼å°æ¯” / Code Comparison\n",
    "\n",
    "#### ğŸ“‹ **èˆŠæ¶æ§‹å­˜å–æ–¹å¼ / Old Architecture Access:**\n",
    "\n",
    "```python\n",
    "# âŒ è¤‡é›œçš„å­—å…¸å¼å­˜å–ï¼Œç„¡ IDE æ”¯æ´\n",
    "analyzer = MainAnalyzer()\n",
    "result = analyzer.load_experiment('experiment.txt')\n",
    "data = analyzer.experiment_data['loaded_files']['topofwd']['data']['image_data']\n",
    "scale = analyzer.experiment_data['txt_data']['scan_parameters']['x_range']\n",
    "\n",
    "# éœ€è¦æ‰‹å‹•ç®¡ç†ç‹€æ…‹\n",
    "# å®¹æ˜“æ‹¼å¯«éŒ¯èª¤\n",
    "# æ²’æœ‰å‹åˆ¥æç¤º\n",
    "# ç‹€æ…‹å¯èƒ½éºå¤±\n",
    "```\n",
    "\n",
    "#### âœ¨ **æ–°æ¶æ§‹å­˜å–æ–¹å¼ / New Architecture Access:**\n",
    "\n",
    "```python\n",
    "# âœ… ç›´è¦ºçš„å±¬æ€§å­˜å–ï¼Œå®Œæ•´ IDE æ”¯æ´\n",
    "session = ExperimentSession('experiment.txt')\n",
    "topo = session['topofwd']           # FileProxy with full type hints\n",
    "data = topo.data.image              # TopoData.image: np.ndarray\n",
    "scale = topo.data.x_range           # TopoData.x_range: float\n",
    "\n",
    "# è‡ªå‹•ç‹€æ…‹ç®¡ç†\n",
    "# å‹åˆ¥å®‰å…¨\n",
    "# IDE è‡ªå‹•å®Œæˆ\n",
    "# çµ±ä¸€éŒ¯èª¤è™•ç†\n",
    "# æ­£ç¢ºçš„ scale è™•ç†\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ ç¸½çµèˆ‡ä¸‹ä¸€æ­¥ / Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ æ–°æ¶æ§‹å„ªå‹¢ç¸½çµ / New Architecture Advantages\n",
      "============================================================\n",
      "âœ… IDE å‹å¥½çš„å‹åˆ¥æç¤º - å®Œæ•´çš„è‡ªå‹•å®Œæˆå’ŒéŒ¯èª¤æª¢æŸ¥\n",
      "âœ… ç›´è¦ºçš„å±¬æ€§å­˜å– - session['file'].data.attribute\n",
      "âœ… å®Œæ•´çš„ç‹€æ…‹ç®¡ç† - æ‰€æœ‰åˆ†æçµæœè‡ªå‹•æŒä¹…åŒ–\n",
      "âœ… çµ±ä¸€çš„è³‡æ–™æ ¼å¼ - æ¨™æº–åŒ–çš„ ParseResult å’ŒéŒ¯èª¤è™•ç†\n",
      "âœ… æ¸…æ™°çš„è·è²¬åˆ†é›¢ - å‹åˆ¥ç®¡ç†å™¨æ¨¡å¼\n",
      "âœ… æ­£ç¢ºçš„ Scale è™•ç† - å¾ TXT æª”æ¡ˆç²å–æ­£ç¢ºçš„æ•¸å€¼ scale\n",
      "âœ… æ™ºèƒ½å¿«å–ç®¡ç† - è‡ªå‹•æœ€ä½³åŒ–è¨˜æ†¶é«”ä½¿ç”¨\n",
      "âœ… æ‰¹æ¬¡æ“ä½œæ”¯æ´ - é«˜æ•ˆçš„å¤šæª”æ¡ˆè™•ç†\n",
      "âœ… å¼·å¤§çš„æœå°‹åŠŸèƒ½ - æ ¹æ“šè¨Šè™Ÿé¡å‹å’Œæ–¹å‘å¿«é€Ÿå®šä½æª”æ¡ˆ\n",
      "\n",
      "ğŸš€ å»ºè­°çš„ä¸‹ä¸€æ­¥:\n",
      "1. æ ¹æ“šæ‚¨çš„å…·é«”éœ€æ±‚æ¸¬è©¦å„ç¨®æª”æ¡ˆé¡å‹\n",
      "2. å˜—è©¦ä½¿ç”¨åˆ†æå™¨é€²è¡Œå¯¦éš›çš„æ•¸æ“šè™•ç†\n",
      "3. æ¢ç´¢æ‰¹æ¬¡è™•ç†åŠŸèƒ½ä¾†è™•ç†å¤šå€‹æª”æ¡ˆ\n",
      "4. ä½¿ç”¨æœå°‹åŠŸèƒ½ä¾†å¿«é€Ÿå®šä½ç‰¹å®šé¡å‹çš„æª”æ¡ˆ\n",
      "5. å¦‚æœ‰å•é¡Œï¼Œåƒè€ƒ docs/migration_guide_v2.md\n"
     ]
    }
   ],
   "source": [
    "# æœ€çµ‚ç¸½çµ\n",
    "print(\"âœ¨ æ–°æ¶æ§‹å„ªå‹¢ç¸½çµ / New Architecture Advantages\")\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… IDE å‹å¥½çš„å‹åˆ¥æç¤º - å®Œæ•´çš„è‡ªå‹•å®Œæˆå’ŒéŒ¯èª¤æª¢æŸ¥\")\n",
    "print(\"âœ… ç›´è¦ºçš„å±¬æ€§å­˜å– - session['file'].data.attribute\")\n",
    "print(\"âœ… å®Œæ•´çš„ç‹€æ…‹ç®¡ç† - æ‰€æœ‰åˆ†æçµæœè‡ªå‹•æŒä¹…åŒ–\")\n",
    "print(\"âœ… çµ±ä¸€çš„è³‡æ–™æ ¼å¼ - æ¨™æº–åŒ–çš„ ParseResult å’ŒéŒ¯èª¤è™•ç†\")\n",
    "print(\"âœ… æ¸…æ™°çš„è·è²¬åˆ†é›¢ - å‹åˆ¥ç®¡ç†å™¨æ¨¡å¼\")\n",
    "print(\"âœ… æ­£ç¢ºçš„ Scale è™•ç† - å¾ TXT æª”æ¡ˆç²å–æ­£ç¢ºçš„æ•¸å€¼ scale\")\n",
    "print(\"âœ… æ™ºèƒ½å¿«å–ç®¡ç† - è‡ªå‹•æœ€ä½³åŒ–è¨˜æ†¶é«”ä½¿ç”¨\")\n",
    "print(\"âœ… æ‰¹æ¬¡æ“ä½œæ”¯æ´ - é«˜æ•ˆçš„å¤šæª”æ¡ˆè™•ç†\")\n",
    "print(\"âœ… å¼·å¤§çš„æœå°‹åŠŸèƒ½ - æ ¹æ“šè¨Šè™Ÿé¡å‹å’Œæ–¹å‘å¿«é€Ÿå®šä½æª”æ¡ˆ\")\n",
    "\n",
    "print(\"\\nğŸš€ å»ºè­°çš„ä¸‹ä¸€æ­¥:\")\n",
    "print(\"1. æ ¹æ“šæ‚¨çš„å…·é«”éœ€æ±‚æ¸¬è©¦å„ç¨®æª”æ¡ˆé¡å‹\")\n",
    "print(\"2. å˜—è©¦ä½¿ç”¨åˆ†æå™¨é€²è¡Œå¯¦éš›çš„æ•¸æ“šè™•ç†\")\n",
    "print(\"3. æ¢ç´¢æ‰¹æ¬¡è™•ç†åŠŸèƒ½ä¾†è™•ç†å¤šå€‹æª”æ¡ˆ\")\n",
    "print(\"4. ä½¿ç”¨æœå°‹åŠŸèƒ½ä¾†å¿«é€Ÿå®šä½ç‰¹å®šé¡å‹çš„æª”æ¡ˆ\")\n",
    "print(\"5. å¦‚æœ‰å•é¡Œï¼Œåƒè€ƒ docs/migration_guide_v2.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ å¯¦é©—å€åŸŸ / Experimental Section\n",
    "\n",
    "æ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„ cell ä¸­è‡ªç”±æ¸¬è©¦æ–°æ¶æ§‹çš„å„ç¨®åŠŸèƒ½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª è‡ªç”±å¯¦é©—å€åŸŸ - åœ¨é€™è£¡æ¸¬è©¦ä»»ä½•æ‚¨æƒ³è¦çš„åŠŸèƒ½\n",
    "# ğŸ§ª Free experimental area - test any features you want here\n",
    "\n",
    "if 'session' in locals():\n",
    "    print(\"ğŸ§ª å¯¦é©—ç’°å¢ƒå·²æº–å‚™å°±ç·’ï¼\")\n",
    "    print(f\"ğŸ“‹ å¯ç”¨æª”æ¡ˆ: {sum(len(files) for files in session.available_files.values())} å€‹\")\n",
    "    \n",
    "    # ä¾‹å­ 1: æ¸¬è©¦æª”æ¡ˆå¿«é€Ÿå­˜å–\n",
    "    if session.available_files['topo']:\n",
    "        first_topo = session[session.available_files['topo'][0]]\n",
    "        print(f\"ğŸ“Š å¿«é€Ÿå­˜å–æ¸¬è©¦: {first_topo}\")\n",
    "    \n",
    "    # ä¾‹å­ 2: æ¸¬è©¦è¨˜æ†¶é«”ç®¡ç†\n",
    "    print(f\"ğŸ’¾ ç›®å‰è¨˜æ†¶é«”ç‹€æ…‹: {session.get_memory_info()['total_loaded']} å€‹æª”æ¡ˆå·²è¼‰å…¥\")\n",
    "    \n",
    "    # ä¾‹å­ 3: æ¸¬è©¦ Scale ä¿®æ­£ - é¡¯ç¤ºæ­£ç¢ºçš„æ•¸å€¼ scale\n",
    "    if 'topo' in locals():\n",
    "        print(f\"ğŸ”¬ Scale è³‡è¨Šæ¸¬è©¦:\")\n",
    "        print(f\"  - æ•¸å€¼ Scale (å¾ TXT): {topo.data.data_scale}\")\n",
    "        print(f\"  - X åƒç´ å°ºåº¦: {topo.data.pixel_scale_x:.4f} nm/pixel\")\n",
    "        print(f\"  - Y åƒç´ å°ºåº¦: {topo.data.pixel_scale_y:.4f} nm/pixel\")\n",
    "    \n",
    "    # åœ¨é€™è£¡æ·»åŠ æ‚¨çš„å¯¦é©—ç¨‹å¼ç¢¼\n",
    "    # Add your experimental code here\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ è«‹å…ˆåŸ·è¡Œä¸Šé¢çš„åˆå§‹åŒ–ç¨‹å¼ç¢¼\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
